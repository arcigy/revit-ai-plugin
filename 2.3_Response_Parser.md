# 2.3 AI Orchestrator

## üéØ Purpose
The AI Orchestrator is responsible for **interpreting responses from the AI LLM**, orchestrating workflow execution logic, and **sending structured commands to the frontend Execution Engine**.  
It acts as the **central decision layer** of the backend: ensures commands are valid, enriched with context, and logged for memory.

---

## üß± Component Structure

| Component | Description | Type |
|-----------|------------|------|
| `ai_orchestrator.py` | Main class for orchestrating AI workflow | Python Class |
| `response_parser.py` | Parses AI LLM responses into structured workflow objects | Python |
| `memory_manager.py` | Stores and retrieves previous command executions and feedback in Supabase | Python |
| `models.py` | Pydantic models for workflow, actions, and feedback | Python |
| `exceptions.py` | Custom exceptions for orchestration errors | Python |

---

## üß≠ Workflow Overview

[HTTPClient.parse_response()]
‚îÇ
‚ñº
[AIOrchestrator.process_response()]
‚îÇ
‚ñº
[Validate & enrich workflow steps]
‚îÇ
‚ñº
[MemoryManager.store_history()]
‚îÇ
‚ñº
[Return CommandResponse to Frontend]

yaml


---

## üß© Functionality

### 1. Response Processing

- Receives parsed JSON from HTTP Client.  
- Validates workflow structure:
  - Must contain `steps` array.  
  - Each step must have `command` and `parameters`.  
- Enriches workflow with context if needed (e.g., selected elements, active view).

**Python Example:**
```python
class AIOrchestrator:
    def __init__(self, memory_manager):
        self.memory_manager = memory_manager

    def process_response(self, command_request, command_response):
        if not command_response.workflow or not command_response.workflow.steps:
            raise ValueError("Workflow contains no steps.")

        # Enrich each step with context if missing
        for step in command_response.workflow.steps:
            if "active_view" not in step.parameters:
                step.parameters["active_view"] = command_request.active_view
            if "selected_elements" not in step.parameters:
                step.parameters["selected_elements"] = [e.dict() for e in command_request.selected_elements]

        # Store workflow history for future AI memory
        self.memory_manager.store_history(command_request, command_response)
        return command_response
2. Memory Integration (Supabase)
Stores:

request_id

command_text

workflow JSON

user feedback (success/fail + notes)

timestamp

Enables future AI prompts to reference past actions for learning from user corrections.

Python Example:

python

import supabase
from datetime import datetime

class MemoryManager:
    def __init__(self, supabase_url, supabase_key):
        self.client = supabase.create_client(supabase_url, supabase_key)

    def store_history(self, command_request, command_response):
        data = {
            "request_id": str(command_request.request_id),
            "command_text": command_request.command_text,
            "workflow": command_response.workflow.json(),
            "errors": command_response.errors,
            "timestamp": datetime.utcnow().isoformat()
        }
        self.client.table("command_history").insert(data).execute()
3. Feedback Loop
Receives feedback from frontend after execution:

success (bool)

note (optional user comment)

Updates the corresponding history entry in Supabase.

Python Example:

python

def store_feedback(self, request_id: str, success: bool, note: str = None):
    update_data = {
        "success": success,
        "note": note,
        "feedback_timestamp": datetime.utcnow().isoformat()
    }
    self.client.table("command_history").update(update_data).eq("request_id", request_id).execute()
4. Error Handling
Invalid workflow ‚Üí raises ValueError

Missing context ‚Üí enriches automatically

Memory storage failures ‚Üí logs and continues without crashing

Ensures frontend always receives a structured CommandResponse even on errors.

5. Logging
Optional debug logs:

Raw AI response

Parsed workflow

Memory storage results

Useful for tracing misbehaving AI outputs.

Python Example:

python

import logging
logging.basicConfig(level=logging.INFO)

logging.info(f"Processing workflow for request {command_request.request_id}")
logging.info(f"Workflow steps: {[step.command for step in command_response.workflow.steps]}")
‚ö†Ô∏è Key Considerations
Supabase Integration: Ensure proper API keys and roles for writing history.

Data Consistency: Always enrich missing parameters before returning to frontend.

Scalability: Use async database calls for large volume workflows.

Extensibility: Easy to add new AI prompts, multimodal inputs, or additional metadata fields.

Security: Sanitize all inputs/outputs to avoid injection attacks in AI prompts.

üì¶ Suggested File Structure

/Backend
  ‚îú‚îÄ‚îÄ ai_orchestrator.py
  ‚îú‚îÄ‚îÄ response_parser.py
  ‚îú‚îÄ‚îÄ memory_manager.py
  ‚îú‚îÄ‚îÄ models.py
  ‚îî‚îÄ‚îÄ exceptions.py
‚úÖ Objective
After implementing AI Orchestrator:

AI responses are validated, enriched, and ready for frontend execution.

Complete history of commands and feedback is stored in Supabase.

Future AI prompts can leverage memory for improved accuracy.

System is robust, modular, and integrates seamlessly with HTTP Client and Request Builder.